/*
========================================================================================
    nf-core/eqtl Nextflow base config file
========================================================================================
    A 'blank slate' config file, appropriate for general use on most high performance
    compute environments. Assumes that all software is installed and available on
    the PATH. Runs in `local` mode - all jobs will be run on the logged in environment.
----------------------------------------------------------------------------------------
*/
params{
    chunkSize=70
    mem1= 12000


    LIMIX{
        run=false
        callRate=0.95
        blockSize=1500
        hwe=0.0000001
    }

    SAIGE{
        run=false
        nr_expression_pcs=5
        // chromosomes_to_test=[1,2,3,4,5,6,7,8,9,10.11,12,13,14,15,16,17,18,19,20,21,X]
        chromosomes_to_test=[1,2] 
        minMAF=0.05
        minMAC=20
        SPAcutoff=2
        markers_per_chunk=10000
        covariate_obs_columns='' // What andata.obs to use as covariates in SAIGE
        cis_trans_mode = 'cis' // cis|trans -- whether to run in cis or trans mode. If running in cis mode pipeline will use window size to test for associations in the +- surounding window of the TSS.
    }

    TensorQTL{
        run=true
        optimise_pcs = true
        interaction_file='' // to run interaction, provide a TSV with genotype ID and interaction 
        // interaction_file='eQTL_interaction_list.tsv'
        interaction_gsea = false
        interaction_maf = 0.1
        interaction_pc_cor_threshold = 0.25 // Drop PCs correlated with interaction above this threshold. Use 1 if you don not want to drop PCs
        trans_by_cis = false // Run trans-by-cis analysis (all genes, limiting variants) following OPTIM PCs?
        trans_by_cis_variant_list='' // Provide a tsv with variant_id and condition_name OR leave empty to use all lead variants from eGenes
        trans_of_cis=false // Run trans-of-cis eQTL analysis (all variants, limiting genes), following OPTIM PCs?         
        trans_by_cis_pval_threshold = 0.01
        alpha=0.05
        chrom_to_map_trans = '' // Option to run GWAS trans analysis - i.e if you specify 2 in here Tensorqtl will run all genes acros genome against all the SNPs on the chromosome 2.
        aggregation_subentry = '' // Are we running all celltypes or a subset of celltypes available in h5ad file?
        //chromosomes_to_test=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,'X']
        chromosomes_to_test=''
    }

    use_sample_pca = true // Set to false if gene PCA is needed

    covariates{        
        nr_phenotype_pcs = '2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86,88,90,92,94,96,98,100'
        nr_genotype_pcs = 5
        genotype_pcs_file = ''
        extra_covariates_file = ''
        genotype_pc_filters = ''
    }

    genotypes{
        use_gt_dosage = true // whether to use dosage. This will convert the vcf/bed to pgen
        subset_genotypes_to_available=false // if true, then the expression data will be first processed and then the samples availbale in all the expression data will be subset from genotype files
        apply_bcftools_filters=true // if true and vcf file is provided then preprocessing will be done on the files. Whether we want to perform the folowing filters as per bcftools_filters
        preprocessed_bed_file='' //if user already has a bed file then this can be used instead of vcf file, and it will avoid the conversion, this can also be taken from the results/genotypes/plink_genotypes_bed 
        preprocessed_pgen_file='' //if user already has a pgen file then this can be used instead of vcf file, and it will avoid the conversion, this can also be taken from the results/genotypes/plink_genotypes_pgen
        preprocessed_bgen_file ='' // if user has already provided bgen file for Limix conversion will be avoided and this file will be used instead
    }

    outdir='results'
    copy_mode = "rellink"
    split_aggregation_adata=false  // Should we split the andata per condition before proceeding with the agregations and normalisations
    genotype_phenotype_mapping_file=''
    utilise_gpu = false
    gtf_type='gene' //# 'gene|transcript'
    input_tables_column_delimiter = '\t' 
    n_min_cells = '5' // The number of cells for individual to use. 
    n_min_individ = '30' //Do not select less than 25 since this may result in a permutation issue with tensorqtl
    aggregation_method = 'dMean' // can be: dMean, dSum
    position = 'TSS' // [ TSS|midpoint ]this can be TSS (for transcriptome, splicing and rna seq experiments) or midpoint (typically for Chi or ATAC qtls)
    dMean_norm_method = 'log1p_cp10k' // Normlisation method for dMean, can be cp10k or a precomputed normalised counts layer in the anndata file
    inverse_normal_transform = 'TRUE' // Inverse normal trasnform data as part of normalisation
    bcftools_filters = '--max-alleles 2 -m2 -M2 -v snps'
    //plink2_filters = '--allow-extra-chr 0 --chr 1-22 XY --indep-pairwise 250 50 0.2 --snps-only --rm-dup exclude-all'
    plink2_filters = '--allow-extra-chr 0 --chr 1-22 XY --snps-only --rm-dup exclude-all'
    maf = 0.05
    hwe= 0.0000001
    windowSize=1000000
    numberOfPermutations=1000
    filter_method = 'HVG' // filterByExpr|HVG|None
    norm_method = 'DESEQ'  //'DESEQ|TMM'
    percent_of_population_expressed=0.20 // whats the proportion of individuals that has to have the value !=0
    // percent_of_population_expressed=0.40 // INTERACTION whats the proportion of individuals that has to have the value !=0
    cell_percentage_threshold = 0 // % of cells that must express the gene
    tmpdir = "${launchDir}/work"
    

    normalise_before_or_after_aggregation = 'before' // before|after - decission whether to normalise the full dataframe before splitting them in subcategories, or after, i.e normalising per subcategory independently.


    eqtl_container = 'https://yascp.cog.sanger.ac.uk/public/singularity_images/eqtl_29_11_2024.sif'
    eqtl_docker='mercury/eqtl:29_11_2024'
}



process {
    cache = 'lenient'
    // TODO nf-core: Check the defaults for all processes
    cpus   = { check_max( 1    * task.attempt, 'cpus'   ) }
    memory = { check_max( 6.GB * task.attempt, 'memory' ) }
    time   = { check_max( 4.h  * task.attempt, 'time'   ) }
    containerOptions = " --cleanenv --containall -B "+params.tmpdir+":/tmp --env NUMBA_CACHE_DIR='"+params.tmpdir+"' --env MPLCONFIGDIR='"+params.tmpdir+"'"

    errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'retry' }
    maxRetries    = 3
    maxErrors     = '-1'

    // Process-specific resource requirements
    // NOTE - Please try and re-use the labels below as much as possible.
    //        These labels are used and recognised by default in DSL2 files hosted on nf-core/modules.
    //        If possible, it would be nice to keep the same label naming convention when
    //        adding in your local modules too.
    // TODO nf-core: Customise requirements for specific processes.
    // See https://www.nextflow.io/docs/latest/config.html#config-process-selectors
    withLabel:process_low {
        cpus   = { check_max( 2     * task.attempt, 'cpus'    ) }
        memory = { check_max( 12.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 12.h   * task.attempt, 'time'    ) }
        queue = { task.attempt > 1 ? 'long' : 'normal' }
        maxRetries = 1
    }
    withLabel:process_medium {
        cpus   = { check_max( 4     * task.attempt, 'cpus'    ) }
        memory = { check_max( 150.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 6.h   * task.attempt, 'time'    ) }
        queue = { task.attempt > 2 ? 'long' : 'normal' }
        maxRetries = 2
    }
    withLabel:process_high {
        cpus   = { check_max( 12    * task.attempt, 'cpus'    ) }
        memory = { check_max( 100.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 16.h  * task.attempt, 'time'    ) }
    }
    withLabel:process_long {
        time   = { check_max( 20.h  * task.attempt, 'time'    ) }
    }
    withLabel:process_high_memory {
        memory = { check_max( 300.GB * task.attempt, 'memory' ) }
         queue = { task.attempt > 2 ? 'hugemem' : 'normal' }
    }
    withLabel:process_medium_memory {
        memory = { check_max( 200.GB * task.attempt, 'memory' ) }
         queue = { task.attempt > 3 ? 'hugemem' : 'normal' }
        maxRetries = 3
    }

    withLabel:error_ignore {
        errorStrategy = 'ignore'
    }
    withLabel:error_retry {
        errorStrategy = 'retry'
        maxRetries    = 2
    }
    withName: LIMIX{
        errorStrategy = { task.attempt <= 2 ? 'retry' : 'ignore' }
    }


    withLabel: gpu {
        cpus = 1
        maxForks=8
        maxRetries = 1

        errorStrategy = 'retry'
        queue = { task.attempt > 2 ? 'gpu-huge' : 'gpu-normal' }
        clusterOptions = { "-M "+params.mem1*task.attempt+" -R 'select[ngpus>0 && mem>="+params.mem1*task.attempt+"] rusage[ngpus_physical=1.00,mem="+params.mem1*task.attempt+"] span[ptile=1]' -gpu 'mode=exclusive_process'" }
	    memory = '' // set to null '' as already specified in clusterOptions

        time   = { check_max( 6.h   * task.attempt, 'time'    ) }
        containerOptions = {
            workflow.containerEngine == "singularity" ? '--containall --cleanenv --nv -B /tmp':
            ( workflow.containerEngine == "docker" ? '--gpus all': null )
        }
    }

    withName: TENSORQTL{
        errorStrategy = { task.attempt <= 1 ? 'ignore' : 'ignore' }
    }

    withName: SPLIT_PHENOTYPE_DATA{
        memory = { check_max( 72.GB * task.attempt, 'memory'  ) }
        time   = 12.h  
    }



}

singularity {
  enabled = true
  cacheDir   = "${baseDir}/singularity"
  runOptions = '--bind /lustre --no-home'
}

executor{
    name = 'lsf'
    perJobMemLimit = true
    poolSize = 4
    submitRateLimit = '5 sec'
    killBatchSize = 50
    queueSize = 700
}

def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}